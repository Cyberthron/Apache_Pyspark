# Apache_Pyspark

<p>Apache Spark is an open-source cluster-computing framework, built around speed, ease of use, and streaming analytics whereas Python is a general-purpose, high-level programming language. It provides a wide range of libraries and is majorly used for Machine Learning and Real-Time Streaming Analytics.</p>

**Why use Python rather then Scala Or Java**

* Python is very easy to learn and implement.
* It provides simple and comprehensive API.
* With Python, the readability of code, maintenance, and familiarity is far better.
* It provides various options for data visualization, which is difficult using Scala or Java.
* Python comes with a wide range of libraries like numpy, pandas, scikit-learn, seaborn, matplotlib etc.
* It is backed up by a huge and active community.

**Features of Apache Spark**

* Speed:

      Spark runs up to 100 times faster than Hadoop MapReduce for large-scale data processing. It is also able to achieve this speed through controlled partitioning.
      
* Powerful Caching:

      Simple programming layer provides powerful caching and disk persistence capabilities.
    
* Deployment:

      It can be deployed through Mesos, Hadoop via YARN, or Sparkâ€™s own cluster manager.
      
* Real-Time:

      It offers Real-time computation & low latency because of in-memory computation.
      
 * Polyglot:
 
      Spark provides high-level APIs in Java, Scala, Python, and R. Spark code can be written in any of these four languages. It also provides a shell in Scala and Python.
      
